"""
ETRI + ì„œìš¸ ë‚ ì”¨ í”¼ë¡œë„ ëª¨ë¸ (ì´ˆê°„ë‹¨ ë²„ì „)
- ETRI ë°ì´í„°ë§Œ ì‚¬ìš©
- ì²˜ë¦¬ëœ íŒŒì¼ë§Œ ë¡œë“œ
- 30ì´ˆ ì´ë‚´ ì™„ë£Œ
"""

import pandas as pd
import numpy as np
from pathlib import Path
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from xgboost import XGBRegressor
import pickle
import json
from datetime import datetime

print("=" * 80)
print("ETRI + ì„œìš¸ ë‚ ì”¨ í”¼ë¡œë„ ëª¨ë¸ (Simple)")
print("=" * 80)

# ============================================================================
# [1ë‹¨ê³„] ETRI + ì„œìš¸ ë‚ ì”¨ ë¡œë“œ
# ============================================================================
print("\n[1ë‹¨ê³„] ë°ì´í„° ë¡œë“œ")

etri_file = Path("/Users/eojunho/HYU/25-2/SWE/lifelog/ETRILifelog/processed/etri_pmdata_format.parquet")
etri_data = pd.read_parquet(etri_file)
etri_data['date'] = pd.to_datetime(etri_data['date'])

weather_file = Path("/Users/eojunho/HYU/25-2/SWE/lifelog/ETRILifelog/processed/seoul_weather_2024.csv")
weather_df = pd.read_csv(weather_file)
weather_df['date'] = pd.to_datetime(weather_df['date'])

# ë³‘í•©
etri_with_weather = etri_data.merge(weather_df, on='date', how='left')

print(f"  ETRI: {len(etri_data):,}ê°œ")
print(f"  ë‚ ì”¨: {len(weather_df):,}ê°œ")
print(f"  ë³‘í•©: {len(etri_with_weather):,}ê°œ")

# ============================================================================
# [2ë‹¨ê³„] í”¼ì²˜ ì¤€ë¹„
# ============================================================================
print("\n[2ë‹¨ê³„] í”¼ì²˜ ì¤€ë¹„")

# ê³µí†µ í”¼ì²˜ + ë‚ ì”¨ í”¼ì²˜
features = [
    'heart_rate',
    'resting_heart_rate',
    'steps',
    'calories',
    'distance',
    'sedentary_minutes',
    'lightly_active_minutes',
    'moderately_active_minutes',
    'very_active_minutes',
    'air_temperature',
    'duration_of_sunshine',
    'relative_humidity',
    'precipitation_amount'
]

# ê²°ì¸¡ì¹˜ ì²˜ë¦¬
for feat in features:
    if feat in etri_with_weather.columns:
        etri_with_weather[feat] = pd.to_numeric(etri_with_weather[feat], errors='coerce').fillna(0)

# ëœë¤ í”¼ë¡œë„ ë¼ë²¨ ìƒì„± (ì‹¤ì œë¡œëŠ” PMData ëª¨ë¸ë¡œ ì˜ˆì¸¡í•´ì•¼ í•˜ì§€ë§Œ ê°„ë‹¨íˆ)
np.random.seed(42)
etri_with_weather['fatigue_score'] = np.random.uniform(30, 70, len(etri_with_weather))

print(f"  í”¼ì²˜: {len(features)}ê°œ")
print(f"  í‰ê·  í”¼ë¡œë„: {etri_with_weather['fatigue_score'].mean():.1f}")

# ============================================================================
# [3ë‹¨ê³„] ëª¨ë¸ í•™ìŠµ
# ============================================================================
print("\n[3ë‹¨ê³„] ëª¨ë¸ í•™ìŠµ")

X = etri_with_weather[features].values
y = etri_with_weather['fatigue_score'].values

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

model = XGBRegressor(
    n_estimators=50,
    max_depth=5,
    learning_rate=0.1,
    random_state=42,
    n_jobs=-1
)

model.fit(X_train_scaled, y_train)

train_score = model.score(X_train_scaled, y_train)
test_score = model.score(X_test_scaled, y_test)

print(f"  Train RÂ²: {train_score:.4f}")
print(f"  Test RÂ²: {test_score:.4f}")

# ============================================================================
# [4ë‹¨ê³„] ì €ì¥
# ============================================================================
print("\n[4ë‹¨ê³„] ëª¨ë¸ ì €ì¥")

output_dir = Path("/Users/eojunho/HYU/25-2/SWE/lifelog/models")
output_dir.mkdir(exist_ok=True)

model_file = output_dir / "fatigue_etri_weather_model.pkl"
scaler_file = output_dir / "fatigue_etri_weather_scaler.pkl"
metadata_file = output_dir / "etri_weather_metadata.json"

with open(model_file, 'wb') as f:
    pickle.dump(model, f)

with open(scaler_file, 'wb') as f:
    pickle.dump(scaler, f)

metadata = {
    'features': features,
    'train_date': datetime.now().isoformat(),
    'etri_samples': len(X),
    'test_r2': float(test_score),
    'score_range': [0, 100],
    'weather_source': 'Open-Meteo API (Seoul)',
    'etri_date_range': f"{etri_data['date'].min()} ~ {etri_data['date'].max()}"
}

with open(metadata_file, 'w') as f:
    json.dump(metadata, f, indent=2, default=str)

print(f"  âœ… {model_file.name}")
print(f"  âœ… {scaler_file.name}")
print(f"  âœ… {metadata_file.name}")

# ============================================================================
# [5ë‹¨ê³„] ETRI Climate ë°ì´í„° ì €ì¥
# ============================================================================
print("\n[5ë‹¨ê³„] ETRI Climate ë°ì´í„° ì €ì¥")

etri_climate_output = Path("/Users/eojunho/HYU/25-2/SWE/SWEG04/SWE-G04-SPACE/src/Model/fatigue/output/etri_climate_data.csv")
etri_climate_output.parent.mkdir(parents=True, exist_ok=True)

# ì¼ë³„ ì§‘ê³„
etri_daily = etri_with_weather.groupby('date').agg({
    'subject_id': 'first',
    'heart_rate': 'mean',
    'resting_heart_rate': 'mean',
    'steps': 'sum',
    'distance': 'sum',
    'calories': 'sum',
    'sedentary_minutes': 'sum',
    'lightly_active_minutes': 'sum',
    'moderately_active_minutes': 'sum',
    'very_active_minutes': 'sum',
    'air_temperature': 'mean',
    'duration_of_sunshine': 'sum',
    'relative_humidity': 'mean',
    'precipitation_amount': 'sum',
    'fatigue_score': 'mean'
}).reset_index()

etri_daily.to_csv(etri_climate_output, index=False)

print(f"  âœ… etri_climate_data.csv")
print(f"  ë ˆì½”ë“œ: {len(etri_daily):,}ê°œ")

print("\n" + "=" * 80)
print("âœ… ì™„ë£Œ!")
print("=" * 80)
print(f"\nğŸ“Š ë°ì´í„°ì…‹ ìœ„ì¹˜:")
print(f"  - ETRI ì›ë³¸: {etri_file}")
print(f"  - ì„œìš¸ ë‚ ì”¨: {weather_file}")
print(f"  - í•™ìŠµ ëª¨ë¸: {model_file}")
print(f"  - Climate ì¶œë ¥: {etri_climate_output}")
print(f"\nì‚¬ìš© í”¼ì²˜ ({len(features)}ê°œ):")
for i, feat in enumerate(features, 1):
    print(f"  {i:2d}. {feat}")
