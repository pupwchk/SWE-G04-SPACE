#!/usr/bin/env python3
"""
Speech-to-Speech ìŒì„± íŒŒì¼ ê¸°ë°˜ í…ŒìŠ¤íŠ¸
2íšŒ ì™•ë³µ ëŒ€í™” í…ŒìŠ¤íŠ¸
"""
import asyncio
import websockets
import json
import os
import sys
import wave
import struct
from pathlib import Path

# User ID ì½ê¸°
if os.path.exists("test_user_id.txt"):
    with open("test_user_id.txt", "r") as f:
        USER_ID = f.read().strip()
else:
    print("âŒ test_user_id.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
    sys.exit(1)

WS_URL = f"ws://localhost:11325/api/voice/ws/voice/{USER_ID}"


def load_audio_file(file_path: str) -> bytes:
    """
    ìŒì„± íŒŒì¼ ë¡œë“œ (WAV, PCM16, 16kHz, mono)
    í—¤ë”(44 bytes)ë¥¼ ì œì™¸í•œ ìˆœìˆ˜ PCM ë°ì´í„°ë§Œ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    if not os.path.exists(file_path):
        raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")

    if not file_path.endswith('.wav'):
        raise ValueError(f"WAV íŒŒì¼ë§Œ ì§€ì›í•©ë‹ˆë‹¤: {file_path}")

    # wave ëª¨ë“ˆë¡œ í¬ë§· ê²€ì¦
    with wave.open(file_path, 'rb') as wav_file:
        channels = wav_file.getnchannels()
        sample_width = wav_file.getsampwidth()
        framerate = wav_file.getframerate()
        print(f"   íŒŒì¼ ì •ë³´ (wave ëª¨ë“ˆ): {channels}ch, {sample_width*8}bit, {framerate}Hz")
        if channels != 1 or sample_width != 2 or framerate != 16000:
            raise ValueError("ì˜¤ë””ì˜¤ëŠ” 16kHz, 16-bit, mono PCM í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")

    # ì‚¬ìš©ìë‹˜ì˜ ë¶„ì„ì— ë”°ë¼, í—¤ë”ë¥¼ ê±´ë„ˆë›°ê³  ë°ì´í„°ë§Œ ì½ìŠµë‹ˆë‹¤.
    with open(file_path, 'rb') as f:
        f.seek(44)  # 44ë°”ì´íŠ¸ í—¤ë” ê±´ë„ˆë›°ê¸°
        pcm_data = f.read()
        return pcm_data


async def test_conversation_with_audio(audio_files: list):
    """
    ìŒì„± íŒŒì¼ë¡œ 2íšŒ ì™•ë³µ ëŒ€í™” í…ŒìŠ¤íŠ¸

    Args:
        audio_files: ìŒì„± íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸ (ìµœì†Œ 2ê°œ)
    """
    print("=" * 70)
    print("Speech-to-Speech ìŒì„± íŒŒì¼ ê¸°ë°˜ ëŒ€í™” í…ŒìŠ¤íŠ¸")
    print("=" * 70)
    print(f"User ID: {USER_ID}")
    print(f"WebSocket URL: {WS_URL}")
    print(f"í…ŒìŠ¤íŠ¸í•  ìŒì„± íŒŒì¼ ê°œìˆ˜: {len(audio_files)}ê°œ\n")

    try:
        async with websockets.connect(WS_URL, ping_interval=30) as websocket:
            print("âœ… WebSocket ì—°ê²° ì„±ê³µ!\n")

            # ì„¸ì…˜ ì‹œì‘ ë©”ì‹œì§€ ìˆ˜ì‹ 
            response = await asyncio.wait_for(websocket.recv(), timeout=5.0)
            if isinstance(response, str):
                data = json.loads(response)
                print(f"ğŸ“¨ {data.get('type')}: {data.get('message')}")
                print(f"   Session ID: {data.get('session_id')}\n")

            # ìˆ˜ì‹ í•œ ì˜¤ë””ì˜¤ ì €ì¥ìš©
            received_audios = []

            # ê° ìŒì„± íŒŒì¼ë¡œ ëŒ€í™”
            for turn, audio_file in enumerate(audio_files, 1):
                print("=" * 70)
                print(f"ğŸ¤ Turn {turn}: {audio_file}")
                print("=" * 70)

                # ìŒì„± íŒŒì¼ ë¡œë“œ
                try:
                    print(f"ğŸ“‚ ìŒì„± íŒŒì¼ ë¡œë“œ ì¤‘: {audio_file}")
                    audio_data = load_audio_file(audio_file)
                    print(f"âœ… ë¡œë“œ ì™„ë£Œ ({len(audio_data)} bytes, {len(audio_data)/32000:.1f}ì´ˆ)")
                except Exception as e:
                    print(f"âŒ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
                    continue

                # ì˜¤ë””ì˜¤ ì „ì†¡ (ì²­í¬ ë‹¨ìœ„)
                print(f"\nğŸ“¤ ì˜¤ë””ì˜¤ ì „ì†¡ ì¤‘...")
                chunk_size = 4096
                chunks_sent = 0

                for i in range(0, len(audio_data), chunk_size):
                    chunk = audio_data[i:i + chunk_size]
                    await websocket.send(chunk)
                    chunks_sent += 1
                    # ì‹¤ì œ ë…¹ìŒ ì†ë„ ì‹œë®¬ë ˆì´ì…˜ (16kHz, 16bit = 32000 bytes/sec)
                    await asyncio.sleep(len(chunk) / 32000)

                print(f"âœ… ì „ì†¡ ì™„ë£Œ ({chunks_sent}ê°œ ì²­í¬)")

                # ì‘ë‹µ ìƒì„± ìš”ì²­
                print(f"\nğŸ“¤ ì‘ë‹µ ìƒì„± ìš”ì²­ (audio_commit)...")
                await websocket.send(json.dumps({"type": "audio_commit"}))

                # AI ì‘ë‹µ ìˆ˜ì‹ 
                print(f"\nâ³ AI ì‘ë‹µ ëŒ€ê¸° ì¤‘...\n")
                turn_audio = []
                transcript_received = False
                assistant_responded = False
                start_time = asyncio.get_event_loop().time()
                timeout = 20.0

                while True:
                    elapsed = asyncio.get_event_loop().time() - start_time
                    if elapsed > timeout:
                        print(f"âš ï¸ íƒ€ì„ì•„ì›ƒ ({timeout}ì´ˆ)")
                        break

                    try:
                        response = await asyncio.wait_for(
                            websocket.recv(),
                            timeout=min(2.0, timeout - elapsed)
                        )

                        if isinstance(response, bytes):
                            turn_audio.append(response)
                            print(f"ğŸ”Š ì˜¤ë””ì˜¤ ìˆ˜ì‹ : {len(response)} bytes (ì´ {sum(len(a) for a in turn_audio)} bytes)")
                            assistant_responded = True

                        elif isinstance(response, str):
                            data = json.loads(response)
                            msg_type = data.get('type')
                            print(f"ğŸ“¨ ì´ë²¤íŠ¸: {msg_type}")

                            if msg_type == 'transcript' and data.get('role') == 'user':
                                print(f"ğŸ“ [USER]: {data.get('text')}")
                            
                            elif msg_type == 'transcript' and data.get('role') == 'assistant':
                                print(f"ğŸ“ [ASSISTANT]: {data.get('text')}")
                                transcript_received = True
                                assistant_responded = True
                            
                            elif msg_type == 'response.done':
                                print(f"âœ… ì‘ë‹µ ì™„ë£Œ")
                                if assistant_responded:
                                    await asyncio.sleep(1.0)
                                    break
                            
                            elif msg_type == 'error':
                                print(f"âŒ ì—ëŸ¬: {data.get('message')}")
                                break

                    except asyncio.TimeoutError:
                        if assistant_responded:
                            print(f"âœ… ì‘ë‹µ ìˆ˜ì‹  ì™„ë£Œ (íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ëŒ€ê¸° ì¢…ë£Œ)")
                            break
                        else:
                            continue
                    except Exception as e:
                        print(f"âš ï¸ ìˆ˜ì‹  ì¤‘ ì—ëŸ¬: {str(e)}")
                        break

                # ìˆ˜ì‹ í•œ ì˜¤ë””ì˜¤ ì €ì¥
                if turn_audio:
                    total_audio = b''.join(turn_audio)
                    received_audios.append({
                        'turn': turn,
                        'audio': total_audio,
                        'input_file': audio_file
                    })

                    output_file = f"response_turn{turn}.wav"
                    save_as_wav(total_audio, output_file)
                    print(f"\nğŸ’¾ ì‘ë‹µ ì˜¤ë””ì˜¤ ì €ì¥: {output_file} ({len(total_audio)} bytes, {len(total_audio)/32000:.1f}ì´ˆ)")

                print(f"\n{'='*70}\n")

                if turn < len(audio_files):
                    await asyncio.sleep(1.0)

            # ì„¸ì…˜ ì¢…ë£Œ
            print("ğŸ”Œ ì„¸ì…˜ ì¢…ë£Œ ìš”ì²­...")
            await websocket.send(json.dumps({"type": "close"}))
            await asyncio.sleep(0.5)

            # ê²°ê³¼ ìš”ì•½
            print("\n" + "=" * 70)
            print("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
            print("=" * 70)
            print(f"ì´ ëŒ€í™” í„´: {len(audio_files)}íšŒ")
            print(f"AI ì‘ë‹µ ìˆ˜ì‹ : {len(received_audios)}íšŒ")

            for item in received_audios:
                duration = len(item['audio']) / 32000
                print(f"  Turn {item['turn']}: {duration:.1f}ì´ˆ ({item['input_file']})")
            
            print("=" * 70)

            if len(received_audios) < len(audio_files):
                print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: ì¼ë¶€ ì‘ë‹µì„ ìˆ˜ì‹ í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
                return False
            else:
                print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ í„´ ì„±ê³µ!")
                return True

    except websockets.exceptions.WebSocketException as e:
        print(f"âŒ WebSocket ì—ëŸ¬: {str(e)}")
        return False
    except Exception as e:
        print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {str(e)}")
        import traceback
        traceback.print_exc()
        return False


def save_as_wav(pcm_data: bytes, output_file: str):
    """PCM ë°ì´í„°ë¥¼ WAV íŒŒì¼ë¡œ ì €ì¥"""
    with wave.open(output_file, 'wb') as wav_file:
        wav_file.setnchannels(1)
        wav_file.setsampwidth(2)
        wav_file.setframerate(16000)
        wav_file.writeframes(pcm_data)


async def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  Speech-to-Speech ìŒì„± íŒŒì¼ ê¸°ë°˜ í…ŒìŠ¤íŠ¸                          â•‘
â•‘                                                                   â•‘
â•‘  ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” ìŒì„± íŒŒì¼ì„ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©í•˜ì—¬                    â•‘
â•‘  OpenAI Realtime APIì™€ 2íšŒ ì™•ë³µ ëŒ€í™”ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.            â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")

    script_dir = Path(__file__).parent
    audio_files = [str(script_dir / "input1.pcm"), str(script_dir / "input2.pcm")]
    print("=" * 70)
    print("ğŸ¤ ìŒì„± íŒŒì¼ ì„¤ì •")
    print("=" * 70)
    
    all_files_exist = True
    for file_path in audio_files:
        if not os.path.exists(file_path):
            print(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {file_path}")
            all_files_exist = False
    
    if not all_files_exist:
        return 1
        
    print(f"  - Turn 1: {os.path.basename(audio_files[0])}")
    print(f"  - Turn 2: {os.path.basename(audio_files[1])}")
    print("\nâœ… ì§€ì •ëœ íŒŒì¼ë¡œ 2íšŒ ëŒ€í™”ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
    print("=" * 70)

    print("\nâ³ í…ŒìŠ¤íŠ¸ ì‹œì‘...")
    print()

    result = await test_conversation_with_audio(audio_files)

    if result:
        print("\nâœ… ëª¨ë“  í…ŒìŠ¤íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print("\nğŸ“ ìƒì„±ëœ íŒŒì¼:")
        for i in range(1, len(audio_files) + 1):
            output_file = f"response_turn{i}.wav"
            if os.path.exists(output_file):
                print(f"   - {output_file}")
    else:
        print("\nâŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨")
        return 1

    return 0


if __name__ == "__main__":
    try:
        exit_code = asyncio.run(main())
        sys.exit(exit_code)
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ì‚¬ìš©ìê°€ ì¤‘ë‹¨í–ˆìŠµë‹ˆë‹¤.")
        sys.exit(0)
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {str(e)}")
        import traceback
        traceback.print_exc()
        sys.exit(1)