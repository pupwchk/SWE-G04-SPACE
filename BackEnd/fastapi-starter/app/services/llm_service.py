"""
LLM ì„œë¹„ìŠ¤ - OpenAI APIë¥¼ ì‚¬ìš©í•œ AI ì‘ë‹µ ìƒì„±
"""
import os
import json
import logging
from typing import Dict, Any, Optional, List
from openai import AsyncOpenAI

logger = logging.getLogger(__name__)

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = AsyncOpenAI(api_key=os.getenv("OPENAI_API_KEY", ""))


class LLMAction:
    """LLM ì•¡ì…˜ íƒ€ì…"""
    NONE = "NONE"  # ì¼ë°˜ í…ìŠ¤íŠ¸ ì‘ë‹µ


class LLMService:
    """LLM ì„œë¹„ìŠ¤"""
    
    def __init__(self):
        self.model = os.getenv("OPENAI_MODEL", "gpt-4o")
    
    def _build_system_prompt(self, persona: Optional[Dict] = None) -> str:
        """
        ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±

        Args:
            persona: í˜ë¥´ì†Œë‚˜ ì •ë³´ (ë§íˆ¬, ì„±ê²© ë“±)
        """
        base_prompt = """ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìŠ¤ë§ˆíŠ¸í™ˆ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

**ì—­í• :**
- ì‚¬ìš©ìì™€ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”
- ì§‘ì•ˆì¼ ë„ì›€ (ê°€ì „ì œí’ˆ ì œì–´, ì¼ì • ê´€ë¦¬ ë“±)
- ì‚¬ìš©ìì˜ ìƒíƒœ íŒŒì•… (í”¼ë¡œë„, ìŠ¤íŠ¸ë ˆìŠ¤ ë“±)
- ì±„íŒ…ì„ í†µí•´ ì¹œê·¼í•˜ê²Œ ì†Œí†µ

**ì‘ë‹µ í˜•ì‹:**
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:

{
  "action": "NONE",
  "response": "ì‘ë‹µ ë©”ì‹œì§€"
}

**ì¤‘ìš”:**
- í•­ìƒ JSONë§Œ ë°˜í™˜í•˜ì„¸ìš”
- ëª¨ë“  ëŒ€í™”ëŠ” ì±„íŒ…ì„ í†µí•´ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤
- ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•œ ëŒ€í™”ì²´ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”
"""

        if persona:
            base_prompt += f"\n**ë§íˆ¬/ì„±ê²©:**\n{persona.get('description', '')}\n"

        return base_prompt
    
    async def generate_response(
        self,
        user_message: str,
        conversation_history: Optional[List[Dict]] = None,
        persona: Optional[Dict] = None,
        context: Optional[Dict] = None,
        appliance_states: Optional[List[Dict]] = None,
        dialogue_state: Optional[Dict] = None
    ) -> Dict[str, Any]:
        """
        LLM ì‘ë‹µ ìƒì„±

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬
            persona: í˜ë¥´ì†Œë‚˜ ì •ë³´
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ìœ„ì¹˜, ì‹œê°„, ìƒíƒœ ë“±)
            appliance_states: í˜„ì¬ ê°€ì „ ìƒíƒœ ë¦¬ìŠ¤íŠ¸
            dialogue_state: DST ìƒíƒœ (intent, slots)

        Returns:
            {
                "action": "NONE",
                "response": "ì‘ë‹µ ë©”ì‹œì§€",
                ...
            }
        """
        try:
            # ë©”ì‹œì§€ êµ¬ì„±
            messages = [
                {"role": "system", "content": self._build_system_prompt(persona)}
            ]

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€
            if conversation_history:
                messages.extend(conversation_history[-10:])  # ìµœê·¼ 10ê°œë§Œ

            # DST ìƒíƒœ ì¶”ê°€ (í˜„ì¬ ëŒ€í™” ë§¥ë½)
            if dialogue_state and (dialogue_state.get("intent") or dialogue_state.get("slots")):
                dst_str = f"\n\n**ëŒ€í™” ë§¥ë½ (DST):**\n"
                if dialogue_state.get("intent"):
                    dst_str += f"- í˜„ì¬ ì˜ë„: {dialogue_state['intent']}\n"
                if dialogue_state.get("slots"):
                    dst_str += f"- ëŒ€í™” ì¤‘ì¸ ì£¼ì œ: {json.dumps(dialogue_state['slots'], ensure_ascii=False)}\n"
                messages.append({"role": "system", "content": dst_str})

            # ê°€ì „ ìƒíƒœ ì¶”ê°€
            if appliance_states:
                appliance_str = "\n\n**í˜„ì¬ ê°€ì „ ìƒíƒœ:**\n"
                for app in appliance_states:
                    status = "ì¼œì§" if app.get("is_on") else "êº¼ì§"
                    appliance_str += f"- {app['appliance_type']}: {status}"
                    if app.get("is_on") and app.get("current_settings"):
                        appliance_str += f" (ì„¤ì •: {json.dumps(app['current_settings'], ensure_ascii=False)})"
                    appliance_str += "\n"
                messages.append({"role": "system", "content": appliance_str})

            # ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€
            if context:
                context_str = f"\n\n**í˜„ì¬ ìƒí™©:**\n{json.dumps(context, ensure_ascii=False, indent=2)}"
                messages.append({"role": "system", "content": context_str})

            # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
            messages.append({"role": "user", "content": user_message})
            
            # OpenAI API í˜¸ì¶œ
            response = await client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.7,
                response_format={"type": "json_object"}
            )
            
            # ì‘ë‹µ íŒŒì‹±
            content = response.choices[0].message.content
            result = json.loads(content)
            
            logger.info(f"âœ… LLM response: action={result.get('action')}")
            return result
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ Failed to parse LLM response: {e}")
            # Fallback
            return {
                "action": "NONE",
                "response": "ì£„ì†¡í•´ìš”, ì˜ ì´í•´í•˜ì§€ ëª»í–ˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ì£¼ì‹œê² ì–´ìš”?"
            }
        except Exception as e:
            logger.error(f"âŒ LLM error: {str(e)}")
            return {
                "action": "NONE",
                "response": "ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì–´ìš”. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."
            }
    
    async def parse_user_intent(self, user_message: str, context: Optional[Dict] = None) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ì˜ë„ íŒŒì‹± (ì‹œë‚˜ë¦¬ì˜¤ 2ìš©)

        "ë¥ë‹¤" â†’ {"type": "temperature", "condition": "hot"}
        "ê±´ì¡°í•˜ë‹¤" â†’ {"type": "humidity", "condition": "dry"}
        "ê³µê¸° ë‚˜ì˜ë‹¤" â†’ {"type": "air_quality", "condition": "bad"}

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            context: í˜„ì¬ ë‚ ì”¨/ìƒíƒœ ì •ë³´

        Returns:
            {
                "intent_type": "environment_complaint" | "general_chat" | "appliance_request",
                "issues": [
                    {"type": "temperature", "condition": "hot"},
                    {"type": "humidity", "condition": "dry"}
                ],
                "needs_control": true/false
            }
        """
        try:
            prompt = f"""ì‚¬ìš©ìì˜ ë©”ì‹œì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì˜ë„ë¥¼ íŒŒì•…í•˜ì„¸ìš”.

ì‚¬ìš©ì ë©”ì‹œì§€: "{user_message}"

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "intent_type": "environment_complaint" | "general_chat" | "appliance_request",
  "issues": [
    {{"type": "temperature|humidity|air_quality", "condition": "hot|cold|dry|humid|bad"}}
  ],
  "needs_control": true/false,
  "summary": "ê°„ë‹¨í•œ ìš”ì•½"
}}

**ë¶„ë¥˜ ê¸°ì¤€:**
- environment_complaint: "ë¥ë‹¤", "ì¶¥ë‹¤", "ê±´ì¡°í•˜ë‹¤", "ìŠµí•˜ë‹¤", "ê³µê¸° ë‚˜ì˜ë‹¤", "ë‹µë‹µí•˜ë‹¤" ë“± í™˜ê²½ ë¶ˆí¸ í‘œí˜„
  â†’ ì´ ê²½ìš° **ë°˜ë“œì‹œ needs_control: true**
- appliance_request: "ì—ì–´ì»¨ ì¼œì¤˜", "ë¶ˆ ì¼œì¤˜" ë“± ì§ì ‘ì ì¸ ê°€ì „ ì œì–´ ìš”ì²­
  â†’ ì´ ê²½ìš°ë„ **ë°˜ë“œì‹œ needs_control: true**
- general_chat: ì¼ë°˜ ëŒ€í™” ("ì•ˆë…•", "ê³ ë§ˆì›Œ", "ë‚ ì”¨ ì–´ë•Œ?" ë“±)
  â†’ ì´ ê²½ìš°ë§Œ needs_control: false

**condition ê°’:**
- temperature: "hot" (ë¥ë‹¤/ë”ì›Œ) / "cold" (ì¶¥ë‹¤/ì¶”ì›Œ)
- humidity: "dry" (ê±´ì¡°í•˜ë‹¤) / "humid" (ìŠµí•˜ë‹¤)
- air_quality: "bad" (ê³µê¸° ë‚˜ì˜ë‹¤/ë‹µë‹µí•˜ë‹¤)

**ì¤‘ìš”:** ì‚¬ìš©ìê°€ í™˜ê²½ì— ëŒ€í•œ ë¶ˆí¸í•¨ì„ í‘œí˜„í•˜ë©´ ë¬´ì¡°ê±´ needs_control: trueì…ë‹ˆë‹¤!
"""

            if context:
                prompt += f"\n\n**í˜„ì¬ í™˜ê²½:**\n{json.dumps(context, ensure_ascii=False, indent=2)}"

            response = await client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ì˜ë„ íŒŒì‹± ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.3,
                response_format={"type": "json_object"}
            )

            content = response.choices[0].message.content
            result = json.loads(content)

            logger.info(f"âœ… Intent parsed: {result.get('intent_type')}, needs_control={result.get('needs_control')}")
            return result

        except Exception as e:
            logger.error(f"âŒ Intent parsing error: {str(e)}")
            return {
                "intent_type": "general_chat",
                "issues": [],
                "needs_control": False,
                "summary": "íŒŒì‹± ì‹¤íŒ¨"
            }

    async def generate_user_request_suggestion(
        self,
        user_message: str,
        appliance_states: List[Dict[str, Any]],
        weather: Dict[str, Any],
        fatigue_level: int,
        persona: Optional[Dict] = None,
        conversation_history: Optional[List[Dict]] = None
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ìš”ì²­ ê¸°ë°˜ ê°€ì „ ì œì–´ ì œì•ˆ (ì¡°ê±´ í…Œì´ë¸” ì—†ì´ LLM íŒë‹¨)

        ì‚¬ìš©ìê°€ "ì¶¥ë‹¤", "ë¥ë‹¤" ë“±ì„ ë§í–ˆì„ ë•Œ, í˜„ì¬ ê°€ì „ ìƒíƒœë¥¼ ë³´ê³  ì œì–´ ì œì•ˆ

        Args:
            user_message: ì‚¬ìš©ì ë©”ì‹œì§€
            appliance_states: í˜„ì¬ ê°€ì „ ìƒíƒœ ë¦¬ìŠ¤íŠ¸
            weather: ë‚ ì”¨ ë°ì´í„°
            fatigue_level: í”¼ë¡œë„ ë ˆë²¨
            persona: í˜ë¥´ì†Œë‚˜ ì •ë³´
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬

        Returns:
            {
                "response": "ì œì•ˆ ë©”ì‹œì§€",
                "appliances": [
                    {
                        "appliance_type": "ì—ì–´ì»¨",
                        "action": "off",
                        "settings": {},
                        "reason": "ì‚¬ìš©ìê°€ ì¶¥ë‹¤ê³  í–ˆìœ¼ë¯€ë¡œ"
                    },
                    ...
                ]
            }
        """
        try:
            # í˜„ì¬ ê°€ì „ ìƒíƒœ ìš”ì•½
            appliance_status_str = ""
            registered_appliances = []

            if appliance_states:
                appliance_status_str = "\n**ì‚¬ìš©ìê°€ ë“±ë¡í•œ ê°€ì „ ëª©ë¡ ë° í˜„ì¬ ìƒíƒœ:**\n"
                for app in appliance_states:
                    status = "ì¼œì§" if app.get("is_on") else "êº¼ì§"
                    appliance_type = app['appliance_type']
                    registered_appliances.append(appliance_type)
                    appliance_status_str += f"- {appliance_type}: {status}"
                    if app.get("is_on") and app.get("current_settings"):
                        appliance_status_str += f" (ì„¤ì •: {json.dumps(app['current_settings'], ensure_ascii=False)})"
                    appliance_status_str += "\n"
            else:
                appliance_status_str = "\n**ì‚¬ìš©ìê°€ ë“±ë¡í•œ ê°€ì „ì´ ì—†ìŠµë‹ˆë‹¤.**\n"

            prompt = f"""ì‚¬ìš©ìê°€ "{user_message}"ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤.

**í˜„ì¬ ìƒí™©:**
- ì˜¨ë„: {weather.get('temperature')}Â°C
- ìŠµë„: {weather.get('humidity')}%
- ë¯¸ì„¸ë¨¼ì§€: {weather.get('pm10')} ã/ã¥
- í”¼ë¡œë„ ë ˆë²¨: {fatigue_level} (1:ì¢‹ìŒ, 2:ë³´í†µ, 3:ë‚˜ì¨, 4:ë§¤ìš°ë‚˜ì¨)

{appliance_status_str}

**ì¤‘ìš” ê·œì¹™:**
1. **ì˜¤ì§ ìœ„ì— ë‚˜ì—´ëœ ë“±ë¡ëœ ê°€ì „ë§Œ** ì œì–´ ì œì•ˆí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤
2. ë“±ë¡ë˜ì§€ ì•Šì€ ê°€ì „ì€ ì ˆëŒ€ ì¶”ì²œí•˜ì§€ ë§ˆì„¸ìš”
3. ë“±ë¡ëœ ê°€ì „ì´ ì—†ìœ¼ë©´ appliancesë¥¼ ë¹ˆ ë°°ì—´ë¡œ ë°˜í™˜í•˜ì„¸ìš”

ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë°”íƒ•ìœ¼ë¡œ **ë“±ë¡ëœ ê°€ì „ ì¤‘ì—ì„œë§Œ** ì ì ˆí•œ ì œì–´ë¥¼ ì œì•ˆí•˜ì„¸ìš”.

ì˜ˆì‹œ:
- "ì¶¥ë‹¤" + ì—ì–´ì»¨ì´ ë“±ë¡ë˜ì–´ ìˆìŒ â†’ ì—ì–´ì»¨ ëƒ‰ë°©ì´ ì¼œì ¸ìˆìœ¼ë©´ ë„ê¸° ì œì•ˆ, ì—ì–´ì»¨ ë‚œë°© ëª¨ë“œë¡œ ì¼œê¸° ì œì•ˆ
- "ë¥ë‹¤" + ì—ì–´ì»¨ì´ ë“±ë¡ë˜ì–´ ìˆìŒ â†’ ì—ì–´ì»¨ ë‚œë°©ì´ ì¼œì ¸ìˆìœ¼ë©´ ë„ê¸° ì œì•ˆ, ì—ì–´ì»¨ ëƒ‰ë°© ëª¨ë“œë¡œ ì¼œê¸° ì œì•ˆ
- "ê±´ì¡°í•˜ë‹¤" + ê°€ìŠµê¸°ê°€ ë“±ë¡ë˜ì–´ ìˆìŒ â†’ ê°€ìŠµê¸° ì¼œê¸° ì œì•ˆ
- "ê±´ì¡°í•˜ë‹¤" + ê°€ìŠµê¸°ê°€ ë“±ë¡ë˜ì–´ ìˆì§€ ì•ŠìŒ â†’ appliances: [] (ë¹ˆ ë°°ì—´)
- "ê³µê¸° ë‚˜ì˜ë‹¤" + ê³µê¸°ì²­ì •ê¸°ê°€ ë“±ë¡ë˜ì–´ ìˆìŒ â†’ ê³µê¸°ì²­ì •ê¸° ì¼œê¸° ì œì•ˆ

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "response": "ì‚¬ìš©ìì—ê²Œ ë³´ë‚¼ ìì—°ìŠ¤ëŸ¬ìš´ ì œì•ˆ ë©”ì‹œì§€",
  "appliances": [
    {{
      "appliance_type": "ë“±ë¡ëœ ê°€ì „ì˜ ì •í™•í•œ ì´ë¦„ (ìœ„ ëª©ë¡ì—ì„œë§Œ ì„ íƒ)",
      "action": "on ë˜ëŠ” off",
      "settings": {{}},
      "reason": "ì œì–´ ì´ìœ "
    }}
  ]
}}

**ì¤‘ìš”:**
- actionì´ "on"ì¼ ë•Œë§Œ settingsë¥¼ í¬í•¨í•˜ì„¸ìš”
- actionì´ "off"ì¼ ë•ŒëŠ” settingsë¥¼ ë¹ˆ ê°ì²´ {{}}ë¡œ í•˜ì„¸ìš”
- power_stateëŠ” settingsì— í¬í•¨í•˜ì§€ ë§ˆì„¸ìš” (is_onìœ¼ë¡œ ë³„ë„ ê´€ë¦¬)

**ê°€ì „ë³„ settings í˜•ì‹ (action: "on"ì¼ ë•Œ):**

ì—ì–´ì»¨:
{{"mode": "ëƒ‰ë°©", "target_temp_c": 23, "fan_speed": 3}}
- mode: "ëƒ‰ë°©", "ì œìŠµ", "ì†¡í’", "ìë™", "ë‚œë°©" ì¤‘ í•˜ë‚˜
- target_temp_c: 18~28 (ì •ìˆ˜)
- fan_speed: 1~5 (ì •ìˆ˜)

ì¡°ëª…:
{{"brightness_pct": 80, "color_temperature_k": 3000}}
- scene: "ì§‘ì¤‘", "íœ´ì‹", "ìˆ˜ë©´" (ì„ íƒ, scene ì‚¬ìš© ì‹œ ë‹¤ë¥¸ ì„¤ì • ìƒëµ ê°€ëŠ¥)
- brightness_pct: 0~100 (ì •ìˆ˜)
- color_temperature_k: 2700~6500, 100 ë‹¨ìœ„ (ì„ íƒ)
- color_hex: "#RRGGBB" í˜•ì‹ (ì„ íƒ)

ê³µê¸°ì²­ì •ê¸°:
{{"mode": "ìë™", "fan_speed": 3}}
- mode: "ìë™", "ìˆ˜ë™", "ì €ì†ŒìŒ" ì¤‘ í•˜ë‚˜
- fan_speed: 1~5 (ì •ìˆ˜)
- target_pm2_5: ëª©í‘œ ë¯¸ì„¸ë¨¼ì§€ ìˆ˜ì¹˜ (ì„ íƒ)
- target_pm10: ëª©í‘œ ë¯¸ì„¸ë¨¼ì§€ ìˆ˜ì¹˜ (ì„ íƒ)
- ionizer_on: true/false (ì„ íƒ)

ì œìŠµê¸°:
{{"mode": "ì¼ë°˜", "target_humidity_pct": 45, "fan_speed": 2}}
- mode: "ì¼ë°˜", "ì—°ì†", "ì„¸íƒë¬¼" ì¤‘ í•˜ë‚˜
- target_humidity_pct: 35~60 (ì •ìˆ˜)
- fan_speed: 1~4 (ì •ìˆ˜)

ê°€ìŠµê¸°:
{{"mode": "ìë™", "target_humidity_pct": 50, "mist_level": 2}}
- mode: "ìë™", "ìˆ˜ë©´", "ì¾Œì " ì¤‘ í•˜ë‚˜
- target_humidity_pct: 40~65 (ì •ìˆ˜)
- mist_level: 1~4 (ì •ìˆ˜)
- warm_mist: true/false (ì„ íƒ)

TV:
{{"input_source": "OTT", "volume": 30, "brightness": 70}}
- input_source: "HDMI 1", "OTT", "ê²Œì„", "ìŒì•…" ì¤‘ í•˜ë‚˜
- volume: 0~100 (ì •ìˆ˜)
- brightness: 30~100 (ì •ìˆ˜)
- channel: ì±„ë„ ë²ˆí˜¸ (ì„ íƒ)
- contrast: ëŒ€ë¹„ ê°’ (ì„ íƒ)
- color: ìƒ‰ìƒ ê°’ (ì„ íƒ)

**ë‹¤ì‹œ í•œë²ˆ ê°•ì¡°:**
- **ë°˜ë“œì‹œ ë“±ë¡ëœ ê°€ì „ë§Œ** appliancesì— í¬í•¨ì‹œí‚¤ì„¸ìš”
- ë“±ë¡ë˜ì§€ ì•Šì€ ê°€ì „ì„ ì¶”ì²œí•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤
- appliance_typeì€ ìœ„ ëª©ë¡ì˜ ê°€ì „ ì´ë¦„ê³¼ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤
- ë“±ë¡ëœ ê°€ì „ì´ ì—†ê±°ë‚˜ ì ì ˆí•œ ê°€ì „ì´ ì—†ìœ¼ë©´ appliancesë¥¼ ë¹ˆ ë°°ì—´ë¡œ í•˜ê³  responseì—ì„œ ë“±ë¡ëœ ê°€ì „ì´ ì—†ë‹¤ê³  ì•ˆë‚´í•˜ì„¸ìš”
"""

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (í˜ë¥´ì†Œë‚˜ ì ìš©)
            system_prompt = self._build_system_prompt(persona)

            response = await client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                response_format={"type": "json_object"}
            )

            content = response.choices[0].message.content
            result = json.loads(content)

            logger.info(f"âœ… User request suggestion generated: {len(result.get('appliances', []))} appliances")
            return result

        except Exception as e:
            logger.error(f"âŒ User request suggestion error: {str(e)}")
            return {
                "response": "ì£„ì†¡í•´ìš”, í˜„ì¬ ì œì–´ ê°€ëŠ¥í•œ ê°€ì „ì„ ì°¾ì§€ ëª»í–ˆì–´ìš”.",
                "appliances": []
            }

    async def generate_proactive_appliance_message(
        self,
        appliances: List[Dict[str, Any]],
        weather: Dict[str, Any],
        fatigue_level: int,
        persona: Optional[Dict] = None,
        conversation_history: Optional[List[Dict]] = None
    ) -> str:
        """
        ì§‘ ë„ì°© ì‹œ ê°€ì „ ì œì–´ ì œì•ˆ ë©”ì‹œì§€ ìƒì„± (Proactive - ì‹œë‚˜ë¦¬ì˜¤ 1ìš©)

        Args:
            appliances: ì œì–´í•  ê°€ì „ ëª©ë¡
            weather: ë‚ ì”¨ ë°ì´í„°
            fatigue_level: í”¼ë¡œë„ ë ˆë²¨ (1-4)
            persona: í˜ë¥´ì†Œë‚˜ ì •ë³´ (nickname)
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)

        Returns:
            ìì—°ìŠ¤ëŸ¬ìš´ ì œì•ˆ ë©”ì‹œì§€
        """
        try:
            appliance_info = []
            for app in appliances:
                info_parts = [f"- {app['appliance_type']}"]
                if app.get('settings'):
                    # ì„¤ì •ê°’ì„ ìì—°ìŠ¤ëŸ½ê²Œ í‘œí˜„
                    settings = app['settings']
                    if 'target_temp_c' in settings:
                        info_parts.append(f"{settings['target_temp_c']}Â°C")
                    if 'mode' in settings:
                        info_parts.append(f"{settings['mode']} ëª¨ë“œ")
                    if 'target_humidity_pct' in settings:
                        info_parts.append(f"ìŠµë„ {settings['target_humidity_pct']}%")
                    if 'fan_speed' in settings:
                        info_parts.append(f"í’ì† {settings['fan_speed']}")
                    if 'brightness_pct' in settings:
                        info_parts.append(f"ë°ê¸° {settings['brightness_pct']}%")

                appliance_info.append(" ".join(info_parts))

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½
            history_context = ""
            if conversation_history and len(conversation_history) > 0:
                history_context = "\n**ì´ì „ ëŒ€í™” ë‚´ìš©:**\n"
                history_context += "ìœ„ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì°¸ê³ í•˜ì—¬, ì´ì „ ëŒ€í™”ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ëŠ” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"

            prompt = f"""ì‚¬ìš©ìê°€ ì§‘ì— ê±°ì˜ ë„ì°©í–ˆìŠµë‹ˆë‹¤.
{history_context}
**í˜„ì¬ ìƒí™©:**
- ì˜¨ë„: {weather.get('temperature')}Â°C
- ìŠµë„: {weather.get('humidity')}%
- í”¼ë¡œë„ ë ˆë²¨: {fatigue_level} (1:ì¢‹ìŒ, 2:ë³´í†µ, 3:ë‚˜ì¨, 4:ë§¤ìš°ë‚˜ì¨)

**AIê°€ ë¶„ì„í•˜ì—¬ ì¶”ì²œí•˜ëŠ” ê°€ì „ ì œì–´:**
{chr(10).join(appliance_info)}

ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ **ì±„íŒ…ìœ¼ë¡œ** ê°€ì „ ì œì–´ë¥¼ ì œì•ˆí•˜ëŠ” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
**ì¤‘ìš”: ì´ì „ ëŒ€í™”ê°€ ìˆë‹¤ë©´, ê·¸ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ëŒ€í™”ë¥¼ ì‘ì„±í•˜ì„¸ìš”.**

**ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:**
1. í˜„ì¬ ìƒí™©(ì˜¨ë„, ìŠµë„, í”¼ë¡œë„)ì„ **ê°„ë‹¨íˆ** í•œ ë¬¸ì¥ìœ¼ë¡œ ì–¸ê¸‰
2. ê° ê°€ì „ì˜ êµ¬ì²´ì ì¸ ì„¤ì •ê°’ì„ ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨
3. "ì‘ë™ì‹œí‚¬ê¹Œìš”?", "ì¼œë“œë¦´ê¹Œìš”?" ê°™ì€ ìŠ¹ì¸ ìš”ì²­ìœ¼ë¡œ ë§ˆë¬´ë¦¬
4. í˜•ì‹ì ì¸ ë‚˜ì—´(ì˜ˆ: "- ì˜¨ë„: XÂ°C") ëŒ€ì‹  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ ì‚¬ìš©
5. **ì ˆëŒ€ë¡œ** "ì „í™” ë“œë¦´ê²Œìš”", "í†µí™”" ê°™ì€ í‘œí˜„ ì‚¬ìš© ê¸ˆì§€ (ì±„íŒ… ë©”ì‹œì§€ì…ë‹ˆë‹¤!)
6. 200ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ

**ì¢‹ì€ ì˜ˆì‹œ:**
- "ì§‘ì— ê±°ì˜ ë„ì°©í•˜ì…¨ë„¤ìš”! ë‚ ì”¨ê°€ ì¶¥ê³  í”¼ë¡œí•´ ë³´ì´ì‹œë‹ˆ ì—ì–´ì»¨ì„ 25ë„ ë‚œë°© ëª¨ë“œë¡œ ë¯¸ë¦¬ ì¼œë“œë¦´ê¹Œìš”?"
- "ê³§ ë„ì°©í•˜ì‹œê² ì–´ìš”! ì§€ê¸ˆ ì˜¨ë„ê°€ ë‚®ê³  ê±´ì¡°í•´ì„œ ì—ì–´ì»¨ì„ 23ë„ë¡œ, ê°€ìŠµê¸°ë¥¼ ìŠµë„ 50%ë¡œ ì¼œë“œë¦´ê¹Œìš”?"

**ë‚˜ìœ ì˜ˆì‹œ (ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”):**
- "ì§‘ì— ê±°ì˜ ë„ì°©í•˜ì…¨ë„¤ìš”!\n\ní˜„ì¬ ìƒí™©:\n- í”¼ë¡œë„ ë ˆë²¨: 1\n- ì˜¨ë„: -1.2Â°C\n..." (í˜•ì‹ì  ë‚˜ì—´)
- "ì¶”ì²œ ê°€ì „:\n- ì—ì–´ì»¨ (target_temp_c: 25, fan_speed: 3)..." (ê¸°ìˆ ì  í‘œí˜„)
- "ì „í™” ë“œë¦´ê²Œìš”", "í†µí™” ê±¸ê²Œìš”" (ì „í™” ì–¸ê¸‰ ê¸ˆì§€!)

ë°˜ë“œì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (JSON ì•„ë‹˜).
"""

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìŠ¤ë§ˆíŠ¸í™ˆ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”."
            if persona:
                system_prompt += f"\në‹¹ì‹ ì˜ ì´ë¦„ì€ {persona.get('nickname')}ì…ë‹ˆë‹¤."

            # ë©”ì‹œì§€ êµ¬ì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
            messages = [{"role": "system", "content": system_prompt}]

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 5ê°œë§Œ)
            if conversation_history:
                messages.extend(conversation_history[-5:])

            messages.append({"role": "user", "content": prompt})

            response = await client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.8,
                max_tokens=150
            )

            message = response.choices[0].message.content.strip()
            logger.info(f"âœ… Proactive appliance message generated: {message[:50]}...")
            return message

        except Exception as e:
            logger.error(f"âŒ Proactive appliance message error: {str(e)}")
            # Fallback
            appliance_names = [a["appliance_type"] for a in appliances]
            return f"ì§‘ì— ê±°ì˜ ë„ì°©í•˜ì…¨ë„¤ìš”! í˜„ì¬ ë‚ ì”¨ì™€ í”¼ë¡œë„ë¥¼ ê³ ë ¤í•´ì„œ {', '.join(appliance_names)}ì„(ë¥¼) ì¼œë“œë¦´ê¹Œìš”?"

    async def generate_proactive_no_appliance_message(
        self,
        weather: Dict[str, Any],
        fatigue_level: int,
        persona: Optional[Dict] = None,
        conversation_history: Optional[List[Dict]] = None
    ) -> str:
        """
        ì§‘ ë„ì°© ì‹œ ê°€ì „ ì¶”ì²œì´ ì—†ì„ ë•Œ ë©”ì‹œì§€ ìƒì„± (Proactive - ì‹œë‚˜ë¦¬ì˜¤ 1ìš©)

        Args:
            weather: ë‚ ì”¨ ë°ì´í„°
            fatigue_level: í”¼ë¡œë„ ë ˆë²¨ (1-4)
            persona: í˜ë¥´ì†Œë‚˜ ì •ë³´ (nickname)
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì»¨í…ìŠ¤íŠ¸ ìœ ì§€)

        Returns:
            ìì—°ìŠ¤ëŸ¬ìš´ ì¸ì‚¬ ë©”ì‹œì§€
        """
        try:
            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ìš”ì•½
            history_context = ""
            if conversation_history and len(conversation_history) > 0:
                history_context = "\n**ì´ì „ ëŒ€í™” ë‚´ìš©:**\n"
                history_context += "ìœ„ ëŒ€í™” íˆìŠ¤í† ë¦¬ë¥¼ ì°¸ê³ í•˜ì—¬, ì´ì „ ëŒ€í™”ì™€ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ëŠ” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"

            prompt = f"""ì‚¬ìš©ìê°€ ì§‘ì— ê±°ì˜ ë„ì°©í–ˆìŠµë‹ˆë‹¤.
{history_context}
**í˜„ì¬ ìƒí™©:**
- ì˜¨ë„: {weather.get('temperature')}Â°C
- ìŠµë„: {weather.get('humidity')}%
- í”¼ë¡œë„ ë ˆë²¨: {fatigue_level} (1:ì¢‹ìŒ, 2:ë³´í†µ, 3:ë‚˜ì¨, 4:ë§¤ìš°ë‚˜ì¨)

AI ë¶„ì„ ê²°ê³¼, í˜„ì¬ ë‚ ì”¨ì™€ í”¼ë¡œë„ ìƒíƒœê°€ ì ì • ë²”ìœ„ë¼ ë”°ë¡œ ì¼¤ ê°€ì „ì€ ì—†ìŠµë‹ˆë‹¤.

ì‚¬ìš©ìì—ê²Œ ì¹œê·¼í•˜ê²Œ ì§‘ ë„ì°©ì„ í™˜ì˜í•˜ëŠ” ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”.
**ì¤‘ìš”: ì´ì „ ëŒ€í™”ê°€ ìˆë‹¤ë©´, ê·¸ ë§¥ë½ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ëŒ€í™”ë¥¼ ì‘ì„±í•˜ì„¸ìš”.**

**ë°˜ë“œì‹œ ì§€ì¼œì•¼ í•  ê·œì¹™:**
1. í˜„ì¬ ìƒíƒœê°€ ê´œì°®ë‹¤ëŠ” ê²ƒì„ ìì—°ìŠ¤ëŸ½ê²Œ ì „ë‹¬
2. í•„ìš”í•˜ë©´ ì–¸ì œë“  ë§í•˜ë¼ëŠ” ì•ˆë‚´
3. 100ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ
4. í˜•ì‹ì ì¸ ë‚˜ì—´ ëŒ€ì‹  ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´

**ì¢‹ì€ ì˜ˆì‹œ:**
- "ì§‘ì— ê±°ì˜ ë„ì°©í•˜ì…¨ë„¤ìš”! í˜„ì¬ ë‚ ì”¨ì™€ ì»¨ë””ì…˜ì´ ê´œì°®ì•„ ë³´ì—¬ìš”. í•„ìš”í•œ ê²Œ ìˆìœ¼ë©´ ì–¸ì œë“  ë§ì”€í•´ì£¼ì„¸ìš”!"
- "ê³§ ë„ì°©í•˜ì‹œê² ì–´ìš”! ì§€ê¸ˆ ìƒíƒœê°€ ì¢‹ì•„ ë³´ì´ë„¤ìš”. í¸íˆ ì‰¬ì„¸ìš”~"

ë°˜ë“œì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (JSON ì•„ë‹˜).
"""

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
            system_prompt = "ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìŠ¤ë§ˆíŠ¸í™ˆ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì„¸ìš”."
            if persona:
                system_prompt += f"\në‹¹ì‹ ì˜ ì´ë¦„ì€ {persona.get('nickname')}ì…ë‹ˆë‹¤."

            # ë©”ì‹œì§€ êµ¬ì„± (ëŒ€í™” íˆìŠ¤í† ë¦¬ í¬í•¨)
            messages = [{"role": "system", "content": system_prompt}]

            # ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¶”ê°€ (ìµœê·¼ 5ê°œë§Œ)
            if conversation_history:
                messages.extend(conversation_history[-5:])

            messages.append({"role": "user", "content": prompt})

            response = await client.chat.completions.create(
                model=self.model,
                messages=messages,
                temperature=0.8,
                max_tokens=100
            )

            message = response.choices[0].message.content.strip()
            logger.info(f"âœ… Proactive no-appliance message generated: {message[:50]}...")
            return message

        except Exception as e:
            logger.error(f"âŒ Proactive no-appliance message error: {str(e)}")
            return "ì§‘ì— ê±°ì˜ ë„ì°©í•˜ì…¨ë„¤ìš”! í˜„ì¬ ë‚ ì”¨ì™€ í”¼ë¡œë„ ìƒíƒœê°€ ê´œì°®ì•„ ë³´ì—¬ìš”. í¸íˆ ì‰¬ì„¸ìš”!"

    async def generate_appliance_suggestion(
        self,
        appliances: List[Dict[str, Any]],
        weather: Dict[str, Any],
        fatigue_level: int,
        user_message: str,
        persona: Optional[Dict] = None,
        appliance_states: Optional[List[Dict]] = None,
        conversation_history: Optional[List[Dict]] = None
    ) -> str:
        """
        ê°€ì „ ì œì–´ ì œì•ˆ ë©”ì‹œì§€ ìƒì„± (ì‹œë‚˜ë¦¬ì˜¤ 2ìš©)

        Args:
            appliances: ì œì–´í•  ê°€ì „ ëª©ë¡
            weather: ë‚ ì”¨ ë°ì´í„°
            fatigue_level: í”¼ë¡œë„ ë ˆë²¨
            user_message: ì‚¬ìš©ì ì›ë³¸ ë©”ì‹œì§€
            persona: í˜ë¥´ì†Œë‚˜ ì •ë³´ (nickname, description)
            appliance_states: í˜„ì¬ ê°€ì „ ìƒíƒœ ë¦¬ìŠ¤íŠ¸
            conversation_history: ëŒ€í™” íˆìŠ¤í† ë¦¬

        Returns:
            ì œì•ˆ ë©”ì‹œì§€ (ì˜ˆ: "í˜„ì¬ ì˜¨ë„ê°€ 28ë„ë¡œ ë†’ê³ , í”¼ë¡œë„ê°€ 3ì´ì—ìš”. ì—ì–´ì»¨ì„ 23ë„ë¡œ ì¼œê³ , ê³µê¸°ì²­ì •ê¸°ë„ ì¼¤ê¹Œìš”?")
        """
        try:
            appliance_info = []
            has_preference_settings = False

            for app in appliances:
                settings_source = app.get('settings_source', 'default')

                # ì„ í˜¸ ì„¸íŒ… ì‚¬ìš© ì—¬ë¶€ í‘œì‹œ
                if settings_source == "preference":
                    has_preference_settings = True
                    source_label = " [í•™ìŠµëœ ì„ í˜¸ ì„¸íŒ…]"
                elif settings_source == "user_input":
                    source_label = " [ì‚¬ìš©ì ì§€ì •ê°’]"
                else:
                    source_label = ""

                info = f"{app['appliance_type']}: {app['settings']}{source_label}"
                if app.get('reason'):
                    info += f" ({app['reason']})"
                appliance_info.append(info)

            prompt = f"""ì‚¬ìš©ìê°€ "{user_message}"ë¼ê³  ë§í–ˆìŠµë‹ˆë‹¤.

**í˜„ì¬ ìƒí™©:**
- ì˜¨ë„: {weather.get('temperature')}Â°C
- ìŠµë„: {weather.get('humidity')}%
- ë¯¸ì„¸ë¨¼ì§€: {weather.get('pm10')} ã/ã¥
- í”¼ë¡œë„ ë ˆë²¨: {fatigue_level} (1:ì¢‹ìŒ, 2:ë³´í†µ, 3:ë‚˜ì¨, 4:ë§¤ìš°ë‚˜ì¨)

**ì¶”ì²œ ê°€ì „ ì œì–´ (ë“±ë¡ëœ ê°€ì „ë§Œ):**
{chr(10).join(appliance_info)}
"""

            # í˜„ì¬ ê°€ì „ ìƒíƒœ ì¶”ê°€
            if appliance_states:
                prompt += "\n**ì‚¬ìš©ìê°€ ë“±ë¡í•œ ê°€ì „ì˜ í˜„ì¬ ìƒíƒœ:**\n"
                for app in appliance_states:
                    status = "ì¼œì§" if app.get("is_on") else "êº¼ì§"
                    prompt += f"- {app['appliance_type']}: {status}"
                    if app.get("is_on") and app.get("current_settings"):
                        prompt += f" (ì„¤ì •: {app['current_settings']})"
                    prompt += "\n"

            # ì„ í˜¸ ì„¸íŒ… ì‚¬ìš© ì‹œ ì¶”ê°€ ì§€ì¹¨
            preference_note = ""
            if has_preference_settings:
                preference_note = f"""
**ì¤‘ìš”: í•™ìŠµëœ ì„ í˜¸ ì„¸íŒ… ì‚¬ìš©**
- "[í•™ìŠµëœ ì„ í˜¸ ì„¸íŒ…]" í‘œì‹œê°€ ìˆëŠ” ê°€ì „ì€ **ë°˜ë“œì‹œ "ì§€ë‚œë²ˆ ì„¤ì •í•˜ì…¨ë˜"ì´ë‚˜ "ì„ í˜¸í•˜ì‹œëŠ”"ê³¼ ê°™ì€ í‘œí˜„**ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ì‚¬ìš©ìê°€ ì´ì „ì— í•™ìŠµí•œ ì„¤ì •ì„ì„ ëª…í™•íˆ ì•Œë ¤ì£¼ì„¸ìš”
- í”¼ë¡œë„ ë ˆë²¨ {fatigue_level}ì— ìµœì í™”ëœ ì„¤ì •ì„ì„ ì–¸ê¸‰í•´ë„ ì¢‹ìŠµë‹ˆë‹¤

**ì„ í˜¸ ì„¸íŒ… ì‚¬ìš© ì˜ˆì‹œ:**
- "ì§€ë‚œë²ˆì— ì„¤ì •í•˜ì…¨ë˜ 23ë„ ëƒ‰ë°© ëª¨ë“œë¡œ ì—ì–´ì»¨ì„ ì¼œë“œë¦´ê¹Œìš”?"
- "ì„ í˜¸í•˜ì‹œëŠ” ìŠµë„ 50%ë¡œ ê°€ìŠµê¸°ë¥¼ ì¼œë“œë¦´ê¹Œìš”?"
- "í‰ì†Œ ì„¤ì •í•˜ì…¨ë˜ ìë™ ëª¨ë“œë¡œ ê³µê¸°ì²­ì •ê¸°ë¥¼ ì¼œë“œë¦´ê¹Œìš”?"
"""

            prompt += f"""
ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ ê°€ì „ ì œì–´ë¥¼ ì œì•ˆí•˜ëŠ” ë©”ì‹œì§€ë¥¼ ìƒì„±í•˜ì„¸ìš”.
{preference_note}
**ê¸°ë³¸ ê·œì¹™:**
1. **ë°˜ë“œì‹œ êµ¬ì²´ì ì¸ ì„¤ì •ê°’ì„ í¬í•¨**í•˜ì—¬ ì œì•ˆí•˜ì„¸ìš”
   - ì˜¨ë„(target_temp_c): "23ë„ë¡œ"
   - ìŠµë„(target_humidity_pct): "ìŠµë„ 50%ë¡œ"
   - ëª¨ë“œ(mode): "ëƒ‰ë°© ëª¨ë“œë¡œ", "ìë™ ëª¨ë“œë¡œ"
   - ë°ê¸°(brightness_pct): "ë°ê¸° 80%ë¡œ"
2. ìœ„ì— ë‚˜ì—´ëœ ë“±ë¡ëœ ê°€ì „ë§Œ ì–¸ê¸‰í•˜ì„¸ìš”
3. ë“±ë¡ë˜ì§€ ì•Šì€ ê°€ì „ì€ ì ˆëŒ€ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
4. í˜„ì¬ ìƒí™©(ì˜¨ë„, ìŠµë„ ë“±)ì„ ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ì—¬ ì œì•ˆ ì´ìœ ë¥¼ ì„¤ëª…í•˜ì„¸ìš”

**ì¢‹ì€ ì˜ˆì‹œ (ì¼ë°˜):**
- "í˜„ì¬ ì˜¨ë„ê°€ 28ë„ë¡œ ë†’ë„¤ìš”. ì—ì–´ì»¨ì„ 23ë„ ëƒ‰ë°© ëª¨ë“œë¡œ ì¼œë“œë¦´ê¹Œìš”?"
- "ìŠµë„ê°€ 30%ë¡œ ê±´ì¡°í•˜ë„¤ìš”. ê°€ìŠµê¸°ë¥¼ ìŠµë„ 50% ìë™ ëª¨ë“œë¡œ ì¼œë“œë¦´ê¹Œìš”?"
- "ë¯¸ì„¸ë¨¼ì§€ê°€ 80ã/ã¥ë¡œ ë‚˜ì¨ ìƒíƒœì˜ˆìš”. ê³µê¸°ì²­ì •ê¸°ë¥¼ ìë™ ëª¨ë“œë¡œ ì¼œë“œë¦´ê¹Œìš”?"

**ë‚˜ìœ ì˜ˆì‹œ (ì ˆëŒ€ í•˜ì§€ ë§ˆì„¸ìš”):**
- "ì—ì–´ì»¨ì„ í‹€ì–´ë“œë¦´ê²Œìš”" (ì„¤ì •ê°’ ëˆ„ë½)
- "ê°€ìŠµê¸°ë¥¼ ì¼œë“œë¦´ê¹Œìš”?" (ëª©í‘œ ìŠµë„ ëˆ„ë½)
- "ê³µê¸°ì²­ì •ê¸° ì¼¤ê¹Œìš”?" (ëª¨ë“œ ëˆ„ë½)

ë°˜ë“œì‹œ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (JSON ì•„ë‹˜).
"""

            # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„± (JSON ì‘ë‹µ ì§€ì‹œ ì œê±°)
            system_prompt = f"""ë‹¹ì‹ ì€ ì‚¬ìš©ìì˜ ìŠ¤ë§ˆíŠ¸í™ˆ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì—ê²Œ ìì—°ìŠ¤ëŸ½ê³  ì¹œê·¼í•˜ê²Œ ëŒ€í™”í•˜ì„¸ìš”.
**ì¤‘ìš”: ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. JSON í˜•ì‹ì„ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.**
"""
            if persona:
                system_prompt += f"\n**ë§íˆ¬/ì„±ê²©:**\n{persona.get('description', '')}\n"

            response = await client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7,
                max_tokens=200
            )

            suggestion = response.choices[0].message.content.strip()
            logger.info(f"âœ… Suggestion generated: {suggestion[:50]}...")
            return suggestion

        except Exception as e:
            logger.error(f"âŒ Suggestion generation error: {str(e)}")
            # Fallback
            appliance_names = [a["appliance_type"] for a in appliances]
            return f"í˜„ì¬ ë‚ ì”¨ì™€ í”¼ë¡œë„ë¥¼ ê³ ë ¤í•´ì„œ {', '.join(appliance_names)}ì„(ë¥¼) ì¼œë“œë¦´ê¹Œìš”?"

    async def detect_modification(
        self,
        original_plan: Dict[str, Any],
        user_response: str
    ) -> Dict[str, Any]:
        """
        ì‚¬ìš©ì ìˆ˜ì • ì‚¬í•­ ê°ì§€ (ì‹œë‚˜ë¦¬ì˜¤ 2ìš©)

        ì˜ˆ:
        - "ì—ì–´ì»¨ì€ 24ë„ë¡œ" â†’ {"ì—ì–´ì»¨": {"target_temp_c": 24}}
        - "ê³µê¸°ì²­ì •ê¸°ëŠ” ë„ê³ " â†’ {"ê³µê¸°ì²­ì •ê¸°": {"action": "off"}}
        - "ê·¸ëŒ€ë¡œ í•´ì¤˜" â†’ {}

        Args:
            original_plan: ì›ë˜ ì œì•ˆí–ˆë˜ ê°€ì „ ì œì–´ ê³„íš
            user_response: ì‚¬ìš©ì ì‘ë‹µ

        Returns:
            {
                "has_modification": true/false,
                "modifications": {
                    "ì—ì–´ì»¨": {"target_temp_c": 24},
                    "ê³µê¸°ì²­ì •ê¸°": {"action": "off"}
                },
                "approved": true/false
            }
        """
        try:
            appliances_str = json.dumps([
                {
                    "appliance_type": a["appliance_type"],
                    "settings": a.get("settings", {})
                }
                for a in original_plan.get("appliances", [])
            ], ensure_ascii=False, indent=2)

            prompt = f"""ì›ë˜ ì œì•ˆ:
{appliances_str}

ì‚¬ìš©ì ì‘ë‹µ: "{user_response}"

ì‚¬ìš©ìê°€ ìˆ˜ì •ì„ ìš”ì²­í–ˆëŠ”ì§€, ê·¸ëŒ€ë¡œ ìŠ¹ì¸í–ˆëŠ”ì§€, ê±°ë¶€í–ˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "approved": true/false,
  "has_modification": true/false,
  "modifications": {{
    "ê°€ì „ì¢…ë¥˜": {{"ì„¤ì •í‚¤": ê°’}}
  }},
  "reason": "íŒë‹¨ ì´ìœ "
}}

**ì˜ˆì‹œ:**
- "ì¢‹ì•„", "ê·¸ë˜", "ì‘" â†’ approved: true, has_modification: false
- "ì—ì–´ì»¨ì€ 24ë„ë¡œ" â†’ approved: true, has_modification: true, modifications: {{"ì—ì–´ì»¨": {{"target_temp_c": 24}}}}
- "ê³µê¸°ì²­ì •ê¸°ëŠ” ë„ê³ " â†’ approved: true, has_modification: true, modifications: {{"ê³µê¸°ì²­ì •ê¸°": {{"action": "off"}}}}
- "ì•„ë‹ˆì•¼", "ê´œì°®ì•„" â†’ approved: false
"""

            response = await client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì‚¬ìš©ì ì‘ë‹µ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.2,
                response_format={"type": "json_object"}
            )

            content = response.choices[0].message.content
            result = json.loads(content)

            logger.info(f"âœ… Modification detected: approved={result.get('approved')}, has_mod={result.get('has_modification')}")
            return result

        except Exception as e:
            logger.error(f"âŒ Modification detection error: {str(e)}")
            return {
                "approved": True,
                "has_modification": False,
                "modifications": {},
                "reason": "íŒŒì‹± ì‹¤íŒ¨ - ì›ë˜ ê³„íš ì‹¤í–‰"
            }


class MemoryService:
    """ëŒ€í™” ë©”ëª¨ë¦¬ ê´€ë¦¬"""

    def __init__(self):
        # ì‹¤ì œë¡œëŠ” DBì— ì €ì¥í•´ì•¼ í•¨
        from collections import OrderedDict
        from datetime import datetime, timedelta

        self.short_term_memory: OrderedDict[str, List[Dict]] = OrderedDict()
        self.long_term_memory: OrderedDict[str, Dict] = OrderedDict()

        # ë©”ëª¨ë¦¬ ì œí•œ ì„¤ì •
        self.MAX_USERS = 200  # ìµœëŒ€ ì‚¬ìš©ì ìˆ˜
        self.MAX_MESSAGES_PER_USER = 50  # ì‚¬ìš©ìë‹¹ ìµœëŒ€ ë©”ì‹œì§€ ìˆ˜
        self.MEMORY_TIMEOUT = timedelta(hours=6)  # 6ì‹œê°„ ë™ì•ˆ ì ‘ê·¼ ì—†ìœ¼ë©´ ì‚­ì œ
        self.last_access: Dict[str, datetime] = {}

    def _cleanup_old_memories(self):
        """ì˜¤ë˜ëœ ë©”ëª¨ë¦¬ ì •ë¦¬"""
        from datetime import datetime
        now = datetime.now()
        to_delete = []

        for user_id in list(self.short_term_memory.keys()):
            last_time = self.last_access.get(user_id, now)
            if now - last_time > self.MEMORY_TIMEOUT:
                to_delete.append(user_id)

        for user_id in to_delete:
            self.short_term_memory.pop(user_id, None)
            self.long_term_memory.pop(user_id, None)
            self.last_access.pop(user_id, None)
            logger.info(f"ğŸ—‘ï¸ Cleaned up memory for user: {user_id}")

        # ìµœëŒ€ ì‚¬ìš©ì ìˆ˜ ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ ê²ƒë¶€í„° ì‚­ì œ (LRU)
        while len(self.short_term_memory) > self.MAX_USERS:
            oldest_user = next(iter(self.short_term_memory))
            self.short_term_memory.pop(oldest_user, None)
            self.long_term_memory.pop(oldest_user, None)
            self.last_access.pop(oldest_user, None)
            logger.info(f"ğŸ—‘ï¸ Evicted memory (max limit): {oldest_user}")

    def add_message(self, user_id: str, role: str, content: str):
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ì— ë©”ì‹œì§€ ì¶”ê°€"""
        from datetime import datetime
        import random

        # 10% í™•ë¥ ë¡œ ì •ë¦¬ ì‹¤í–‰
        if random.random() < 0.1:
            self._cleanup_old_memories()

        if user_id not in self.short_term_memory:
            self.short_term_memory[user_id] = []

        self.short_term_memory[user_id].append({
            "role": role,
            "content": content
        })

        # ìµœê·¼ ë©”ì‹œì§€ë§Œ ìœ ì§€
        if len(self.short_term_memory[user_id]) > self.MAX_MESSAGES_PER_USER:
            self.short_term_memory[user_id] = self.short_term_memory[user_id][-self.MAX_MESSAGES_PER_USER:]

        # ì ‘ê·¼ ì‹œê°„ ê°±ì‹  (LRU)
        self.last_access[user_id] = datetime.now()
        # OrderedDictì—ì„œ ìµœì‹  í•­ëª©ìœ¼ë¡œ ì´ë™
        if user_id in self.short_term_memory:
            self.short_term_memory.move_to_end(user_id)

    def get_history(self, user_id: str, limit: int = 10) -> List[Dict]:
        """ëŒ€í™” íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        from datetime import datetime

        if user_id not in self.short_term_memory:
            return []

        # ì ‘ê·¼ ì‹œê°„ ê°±ì‹ 
        self.last_access[user_id] = datetime.now()
        self.short_term_memory.move_to_end(user_id)

        return self.short_term_memory[user_id][-limit:]

    def update_long_term_memory(self, user_id: str, key: str, value: Any):
        """ì¥ê¸° ë©”ëª¨ë¦¬ ì—…ë°ì´íŠ¸"""
        from datetime import datetime

        if user_id not in self.long_term_memory:
            self.long_term_memory[user_id] = {}

        self.long_term_memory[user_id][key] = value

        # ì ‘ê·¼ ì‹œê°„ ê°±ì‹ 
        self.last_access[user_id] = datetime.now()
        if user_id in self.long_term_memory:
            self.long_term_memory.move_to_end(user_id)

    def get_long_term_memory(self, user_id: str) -> Dict:
        """ì¥ê¸° ë©”ëª¨ë¦¬ ì¡°íšŒ"""
        from datetime import datetime

        if user_id in self.last_access:
            self.last_access[user_id] = datetime.now()
        if user_id in self.long_term_memory:
            self.long_term_memory.move_to_end(user_id)

        return self.long_term_memory.get(user_id, {})


# ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
llm_service = LLMService()
memory_service = MemoryService()
